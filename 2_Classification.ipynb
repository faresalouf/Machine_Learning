{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "protecting-marine",
   "metadata": {},
   "source": [
    "## 1 - Classification in brief"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-anthony",
   "metadata": {},
   "source": [
    "The most common supervised learning tasks are Regression (predicting values i.e quantitative variables) and Classification (predicting classes i.e factors, qualitative variables). In the last notebook, we used Regression models (LinearRegression, DecisionTree, RandomForest). Now we will work on a Classification project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-thickness",
   "metadata": {},
   "source": [
    "We will use the MNIST dataset which is a set of 70 000 small images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. Our dependant variable is a qualitative variable with 9 levels --> 1,2,3,4,5,6,7,8,9. The variable may seem quantitative, but it is not. In fact try and imagine these numbers as not really numbers but just \"names\" or \"labels\". We could have done the same task but instead of the numbers as labels, we used \"one\", \"two\", \"three\",\"four\"...  \n",
    "<br/>\n",
    "So our y/dependant variable is the labels. Our X variables are the pcitures of the handwritten image transformed into vectors. The model we are training will take as input a vector of numbers (that represent the handwritten image) and try to guess what number is written in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-quilt",
   "metadata": {},
   "source": [
    "### Code to download the MNIST  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "static-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "statewide-exclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The variable we created \"mnist\" is a dictionary that has key-values pair; \n",
    "mnist.keys() # .keys() gives the keys of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-tribute",
   "metadata": {},
   "source": [
    "The datasets that we generally load from sklearn have all the same structure (nearly):\n",
    "- <u>data</u>: A matrix that contains n-columns and m-rows. The columns are the features(variables) and the rows the instances(observations)\n",
    "- <u>DESCR</u>: Describes the data.\n",
    "- <u>target</u>: Contains the labels(dependant variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-conservation",
   "metadata": {},
   "source": [
    "### Create our X and y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "worldwide-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fallen-controversy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # We have 784 features and 70 000 instances. Every handwritten drawing is converted into a vector of 784 numbers.\n",
    "\n",
    "# In fact, each image is 28 x 28 pixels which is equivalent de 784 features, each one representing 1 pixel's intensity\n",
    "# from 0(white) to 255(black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conventional-float",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-return",
   "metadata": {},
   "source": [
    "#### Visualize the handwritten numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-sperm",
   "metadata": {},
   "source": [
    "In order to visualize the numbers, we can represent in a graph the 784 data points and convert them to colours with matplotlib's *imshow* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "regulated-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ranking-gospel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of the first drawing is 5.\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X) # Transform the pandas data frame into a numpy array to visualize\n",
    "y = np.array(y)\n",
    "\n",
    "print(f'The label of the first drawing is {y[0]}.') # What is the label of the drawing we will look at in a moment ?\n",
    "\n",
    "some_digit = X[0] # we are taking all the features of the observation number 1 (1 is 0 in python)\n",
    "\n",
    "# iloc is a pandas function that allow to localize using the index.\n",
    "\n",
    "some_digit_image = some_digit.reshape(28,28) # X[0] is an array, vector of numbers; the real image is a 28 x 28 matrix; so\n",
    "\n",
    "# we will reshape the vector into the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "designing-flour",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(some_digit_image, cmap = 'binary') # cmap means colour map --> colour map binary is black and white\n",
    "plt.axis('off') # don't show the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-bookmark",
   "metadata": {},
   "source": [
    "We can see the power of python for visualization. With simple line of codes we could see a whole image. Now we know that the observation number 1 (0 in python) represents number 5. The question is now, how to create a machine learning model that will read this array of 784 numbers and decide that these number represent indeed a number 5. Espacially when we consider this is a handwritten number, meaning that there will be variations within the same number when written by different people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-clark",
   "metadata": {},
   "source": [
    "#### Convert the label from string to number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-briefs",
   "metadata": {},
   "source": [
    "The label column (y) is made of strings. Most ML algorithms love numbers, so let's convert the labels to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "proprietary-release",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # we can see that the elements of the array are strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "apparent-kuwait",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.astype(np.uint8) # convert the type from object to uint8 (integers)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-jumping",
   "metadata": {},
   "source": [
    "#### An example of the dataset (and itscomplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-grammar",
   "metadata": {},
   "source": [
    "<img src=\"Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-thirty",
   "metadata": {},
   "source": [
    "To conclude this first part of the notebook, classification is really a way of taking input (ex: images of handwritten digits) and **classifying** them into categories (ex: category 1: '1', category 2: '5' ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-owner",
   "metadata": {},
   "source": [
    "## 2- Training ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-plasma",
   "metadata": {},
   "source": [
    "### Creating a test and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-terrace",
   "metadata": {},
   "source": [
    "Of course before any ML project we first need to divide our data in 2 parts: training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-queens",
   "metadata": {},
   "source": [
    "We are lucky because the MNIST dataset is already splitted for us in training and testing sets. The first 60 000 images are for training and the last 10 000 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "expressed-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = X[:60000],X[60000:],y[:60000],y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-diversity",
   "metadata": {},
   "source": [
    "### Training a Binary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-subcommittee",
   "metadata": {},
   "source": [
    "Binary Classifiers are classifiers that predict only 2 groups; you are either 1 or 0.  \n",
    "<br/>\n",
    "An example of that would be to train a classifier that will only detect the number 5: the \"5-detector\" classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "undefined-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the target vectors\n",
    "y_train_5 = (y_train == 5) # We will have Tue for all 5 and False if not a 5.\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "# A good practice is always to put these conditional statements between parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-recipe",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent (SGD-Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-grove",
   "metadata": {},
   "source": [
    "We will pick SGD classifier to start with. This classifier has the advantage of being capable of handling very large datasets efficiently. This is in part because SGD deals with training instances independently, one at a time (which also makes SGD well suited for online learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "labeled-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "employed-puzzle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state = 42) # random_state is just so every time we run the notebook we get the same results\n",
    "sgd_clf.fit(X_train,y_train_5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-intranet",
   "metadata": {},
   "source": [
    "**NB**: SGD Classifier relies on randomness during training $\\rightarrow$; hence the name Stochastic; stochasticity being the lacking of any predictable order or plan. This is why we used random_state here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "living-pressure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can use the classifier to detect the number 5.\n",
    "sgd_clf.predict([some_digit]) # Remember that some_digit is X[0] that we say is number 5. Let's see if the classifier\n",
    "# will correctly classify it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-porcelain",
   "metadata": {},
   "source": [
    "Hurrah ! the classifier correctly classified our handwritten image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-costume",
   "metadata": {},
   "source": [
    "## 3- Performance measure of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-india",
   "metadata": {},
   "source": [
    "Now that we have a model, let's measure its performance with cross-valdiation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-spencer",
   "metadata": {},
   "source": [
    "In the previous notebook we saw how to use *cross_val_score* that is the very direct and easy way to implement cross validation. Let's try it with 3 folds. 3 folds means dividing the training set in 3 parts and then trying the model 3 times; training it on 2 folds and testing on the 3rd validation fold by changing after each iteration the validation fold; so that all folds are used 1 times as a validation fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adequate-lingerie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv = 3, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-thing",
   "metadata": {},
   "source": [
    "What a beautiful score ! Above 95% of correct answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-japanese",
   "metadata": {},
   "source": [
    "If it is too good to be true...IT IS TOO GOOD TO BE TRUE.  \n",
    "<br/>\n",
    "Look at that, we will create a very dumb classifier that will just **class every image as not being 5**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "armed-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1), dtype = bool) # Every time the classifier will say FALSE --> not a 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "sorted-barcelona",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91125, 0.90855, 0.90915])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv = 3, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-classic",
   "metadata": {},
   "source": [
    "Wait.. Wuut ??  \n",
    "The super dumb classifier that always says not 5 has a 90-91% accuracy. How come ?  \n",
    "<br/>\n",
    "Well, in the original dataset we have 9 options (1 to 9). The number of 5s is around 10-11%. Therefore a classifier that only detects 5, if it says not 5 every time,  will only be mistaken around 10% of the trials and the accuracy will be at 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-communications",
   "metadata": {},
   "source": [
    "This is an important lesson; it shows that when we deal with skewed data sets (meaning some classes are more frequent then others; like in our case where 90% were False and 10% True), the **accuracy** is not a good performance measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-format",
   "metadata": {},
   "source": [
    "#### Advanced cross valdiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-contractor",
   "metadata": {},
   "source": [
    "In the previous example we used the very direct and easy cross_val_score. However, sometimes we need more control over the cross validation. In these cases, we can adapt cross_val_score to fit our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-minnesota",
   "metadata": {},
   "source": [
    "By default cross_val_score uses StratifiedKFold. Other cross validations exist namely KFold, LeaveOneOut, ShuffleSplit, GroupKFold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-conditioning",
   "metadata": {},
   "source": [
    "The idea would be to create a variable called **cv** and then input it in cross_val_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fuzzy-morocco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95316667, 0.96283333, 0.95116667, 0.96691667, 0.96291667])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, LeaveOneOut, ShuffleSplit, GroupKFold\n",
    "\n",
    "cv = KFold(5)\n",
    "cross_val_score(sgd_clf,X_train,y_train_5,cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-evans",
   "metadata": {},
   "source": [
    "We won't go into details here, but we just wanted to expose the method so you can use it in your project. You can research these cross-val methods and implement them accordingly if and when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-niger",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-smart",
   "metadata": {},
   "source": [
    "The confusion matrix is very useful and it tells us how many of \"A\" were classified as \"A\" and how many as \"B\". Same for \"B\".\n",
    "<br/>\n",
    "This is a much better way to evaluate the performance of a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-destination",
   "metadata": {},
   "source": [
    "To compute the confusion matrix we first need to have a set of predictions so that they can be compared to the actual targets. We could predict on the test set; but remember, ideally we want to keep the test set for the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "unauthorized-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "possible-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "\n",
    "## This function will perform cross validation as before but return the predicted values on the validation sets.\n",
    "## These are \"clean\" predictions because model never saw or is trained on the validation sets. \n",
    "## If we put together all the predictions made on the validation sets, we get y_pred for all our training data;\n",
    "##### because every fold (subset) will become for one iteration a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "located-soundtrack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-syracuse",
   "metadata": {},
   "source": [
    "Each row in the confusion matrix represent an actual class, while each column represent a predicted class.  \n",
    "<br/>\n",
    "The first row of this matrix considers non-5 images (False class) $\\rightarrow$ 53892 of them were correctly classified (**True Negatives**) and 687 wrong (**False Positives**).  \n",
    "<br/>\n",
    "The second row considers the yes-5 images (True class) $\\rightarrow$ 1891 were falsely classified (**False Negatives**) and 3530 were correct (**True Positives**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-jungle",
   "metadata": {},
   "source": [
    "**NB**: A perfect prediction would make a confusion matrix with only True Positives and True Negatives. It would have non zeros only on the main diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-course",
   "metadata": {},
   "source": [
    "#### Accuracy of the positive predictions (Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-saturn",
   "metadata": {},
   "source": [
    "A measure based on the confusion matrix is the accuracy of the positive predictions called **percision** $\\rightarrpw$ positive detected / every positive classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-enzyme",
   "metadata": {},
   "source": [
    "precision = $\\frac {TP}{TP + FP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-grave",
   "metadata": {},
   "source": [
    "#### True positive rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-initial",
   "metadata": {},
   "source": [
    "Precision is usually used with the measure of **sensitivity** or **true positive rate** $\\rightarrow$ this is the ratio of positive instances that are correctly detected by the classifier $\\rightarrow$ positive detected / positive total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-picture",
   "metadata": {},
   "source": [
    "sensitivity = $\\frac{TP}{TP+FN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "spatial-sussex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370879772350012"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision and sensitivity (also called Recall)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "front-cambridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6511713705958311"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-collect",
   "metadata": {},
   "source": [
    "Now our 5-detector does not look as good as with the 0.96 accuracy !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-surgeon",
   "metadata": {},
   "source": [
    "**Interpretation of scores**:   \n",
    "- When the model claims the image is a 5, it is correct 84% of the time.  \n",
    "- The model detects only 65% of the 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-lighter",
   "metadata": {},
   "source": [
    "It is convenient to combine the precision and recall in one metric called the $F_1$ score. In particular if we need a simple way to compare 2 classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-interface",
   "metadata": {},
   "source": [
    "This score is the *harmonic mean* of precision and recall. The regular mean treats all values equally, the harmonic mean gives more weight to low values. As a result, a classifier will only get a high $F_1$ score if both recall and precision are high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-jenny",
   "metadata": {},
   "source": [
    "F1 = $\\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "limited-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7325171197343846"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-journalism",
   "metadata": {},
   "source": [
    "This score favors classifiers that have similar precision and recall. This is not always what we want: in some contexts we mostly care about precision and in others about recall.  \n",
    "<br/>\n",
    "We can't have it both ways, increasing precision reduces recall and vice versa.  \n",
    "<br/>\n",
    "**precision**: When the model claims its positive, it is correct x% of the time.  \n",
    "**recall**: The model detects x% of the positive.  \n",
    "<br/>\n",
    "So we can augment the recall by labeling more observations as positive. It will probably augment the detection of positives but it will reduce the % of correct positives. It will label more of the negatives as positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-frame",
   "metadata": {},
   "source": [
    "### Precision/Recall trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-qualification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py38] *",
   "language": "python",
   "name": "conda-env-.conda-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
